#!/usr/bin/env python3
"""
æµ‹è¯•æœç´¢ç»“æœå¯¼å‡ºåŠŸèƒ½
"""

import asyncio
import json
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.index import (
    export_search_results,
    initialize_search_manager
)


async def test_export_basic():
    """æµ‹è¯•åŸºæœ¬çš„å¯¼å‡ºåŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•åŸºæœ¬çš„æœç´¢ç»“æœå¯¼å‡º")
    print("=" * 60)
    
    # åˆå§‹åŒ–æœç´¢ç®¡ç†å™¨
    await initialize_search_manager()
    
    # å¯¼å‡ºæœç´¢ç»“æœ
    result = await export_search_results(
        query="Python programming",
        num_results=5,
        engine="duckduckgo",
        output_file="test_basic_export.json",
        include_metadata=True
    )
    
    data = json.loads(result)
    print(json.dumps(data, ensure_ascii=False, indent=2))
    
    # éªŒè¯å¯¼å‡ºæˆåŠŸ
    assert data["success"] is True, "å¯¼å‡ºå¤±è´¥"
    assert "output_file" in data, "ç¼ºå°‘è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    assert "file_size_bytes" in data, "ç¼ºå°‘æ–‡ä»¶å¤§å°"
    assert "total_results" in data, "ç¼ºå°‘ç»“æœæ•°é‡"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    output_path = Path(data["output_file"])
    assert output_path.exists(), f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {output_path}"
    
    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
    with open(output_path, 'r', encoding='utf-8') as f:
        exported_data = json.load(f)
    
    assert "results" in exported_data, "å¯¼å‡ºæ•°æ®ç¼ºå°‘ results"
    assert "metadata" in exported_data, "å¯¼å‡ºæ•°æ®ç¼ºå°‘ metadata"
    
    print(f"\nâœ… åŸºæœ¬å¯¼å‡ºæµ‹è¯•é€šè¿‡")
    print(f"   æ–‡ä»¶ä½ç½®: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {data['file_size_bytes']} å­—èŠ‚")
    print(f"   ç»“æœæ•°é‡: {data['total_results']}")


async def test_export_without_metadata():
    """æµ‹è¯•ä¸åŒ…å«å…ƒæ•°æ®çš„å¯¼å‡º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•ä¸åŒ…å«å…ƒæ•°æ®çš„å¯¼å‡º")
    print("=" * 60)
    
    # å¯¼å‡ºæœç´¢ç»“æœï¼ˆä¸åŒ…å«å…ƒæ•°æ®ï¼‰
    result = await export_search_results(
        query="Machine Learning",
        num_results=3,
        engine="auto",
        output_file="test_no_metadata_export.json",
        include_metadata=False
    )
    
    data = json.loads(result)
    print(json.dumps(data, ensure_ascii=False, indent=2))
    
    # éªŒè¯å¯¼å‡ºæˆåŠŸ
    assert data["success"] is True, "å¯¼å‡ºå¤±è´¥"
    
    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
    output_path = Path(data["output_file"])
    with open(output_path, 'r', encoding='utf-8') as f:
        exported_data = json.load(f)
    
    assert "results" in exported_data, "å¯¼å‡ºæ•°æ®ç¼ºå°‘ results"
    assert "metadata" not in exported_data, "ä¸åº”åŒ…å« metadata"
    
    print(f"\nâœ… æ— å…ƒæ•°æ®å¯¼å‡ºæµ‹è¯•é€šè¿‡")


async def test_export_custom_path():
    """æµ‹è¯•è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„")
    print("=" * 60)
    
    # å¯¼å‡ºåˆ°å­ç›®å½•
    result = await export_search_results(
        query="AI test",
        num_results=2,
        engine="duckduckgo",
        output_file="custom/path/test_export.json",
        include_metadata=True
    )
    
    data = json.loads(result)
    print(json.dumps(data, ensure_ascii=False, indent=2))
    
    # éªŒè¯å¯¼å‡ºæˆåŠŸ
    assert data["success"] is True, "å¯¼å‡ºå¤±è´¥"
    
    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
    output_path = Path(data["output_file"])
    assert "custom/path" in str(output_path), "è¾“å‡ºè·¯å¾„ä¸æ­£ç¡®"
    assert output_path.exists(), f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {output_path}"
    
    print(f"\nâœ… è‡ªå®šä¹‰è·¯å¾„å¯¼å‡ºæµ‹è¯•é€šè¿‡")
    print(f"   æ–‡ä»¶ä½ç½®: {output_path}")


async def test_metadata_content():
    """æµ‹è¯•å…ƒæ•°æ®å†…å®¹çš„å®Œæ•´æ€§"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å…ƒæ•°æ®å†…å®¹")
    print("=" * 60)
    
    # å¯¼å‡ºæœç´¢ç»“æœ
    result = await export_search_results(
        query="Test metadata",
        num_results=5,
        engine="duckduckgo",
        output_file="test_metadata_content.json",
        include_metadata=True
    )
    
    data = json.loads(result)
    output_path = Path(data["output_file"])
    
    # è¯»å–å¯¼å‡ºçš„æ–‡ä»¶
    with open(output_path, 'r', encoding='utf-8') as f:
        exported_data = json.load(f)
    
    metadata = exported_data["metadata"]
    
    # éªŒè¯å…ƒæ•°æ®å­—æ®µ
    required_fields = [
        "query", "num_results", "requested_engine",
        "actual_engine", "search_duration_seconds",
        "timestamp", "total_results", "version"
    ]
    
    for field in required_fields:
        assert field in metadata, f"å…ƒæ•°æ®ç¼ºå°‘å­—æ®µ: {field}"
    
    print("å…ƒæ•°æ®å†…å®¹:")
    print(json.dumps(metadata, ensure_ascii=False, indent=2))
    
    print(f"\nâœ… å…ƒæ•°æ®å†…å®¹æµ‹è¯•é€šè¿‡")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯•æœç´¢ç»“æœå¯¼å‡ºåŠŸèƒ½...\n")
    
    try:
        await test_export_basic()
        await test_export_without_metadata()
        await test_export_custom_path()
        await test_metadata_content()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰å¯¼å‡ºæµ‹è¯•é€šè¿‡ï¼")
        print("=" * 60)
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        print("\næ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        output_dir = Path("output")
        if output_dir.exists():
            import shutil
            test_files = [
                "test_basic_export.json",
                "test_no_metadata_export.json",
                "test_metadata_content.json",
                "custom"  # ç›®å½•
            ]
            for item in test_files:
                path = output_dir / item
                if path.exists():
                    if path.is_dir():
                        shutil.rmtree(path)
                    else:
                        path.unlink()
                    print(f"   åˆ é™¤: {path}")
        
        print("âœ… æ¸…ç†å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
